# It is used as an activation function only for the hidden layers

def relu(x):

    if x < 0:
        x = 0

    return x
